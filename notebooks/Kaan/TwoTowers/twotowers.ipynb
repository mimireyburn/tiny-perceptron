{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3933575/928396368.py:49: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql_query(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id                               item_id  \\\n",
      "0    21507  0aa69c75-fe3d-4fa4-b7b6-be5ddb84dc97   \n",
      "1    21507  e51065ff-bf8e-481e-88a9-a73fe0e97bbb   \n",
      "2    21507  cf669ac8-3467-454c-ae6e-d080ac085b4b   \n",
      "3    21507  0aa69c75-fe3d-4fa4-b7b6-be5ddb84dc97   \n",
      "4     2125  fbf59f88-29a6-4877-9c8e-efc7619c9788   \n",
      "\n",
      "                             session_id              cur_evt_unix  type  \\\n",
      "0  f8e41567-0858-4376-ac68-b0701ee23285 2023-07-25 15:38:16+00:00  reco   \n",
      "1  f8e41567-0858-4376-ac68-b0701ee23285 2023-07-25 15:38:21+00:00  reco   \n",
      "2  f8e41567-0858-4376-ac68-b0701ee23285 2023-07-25 15:38:23+00:00  reco   \n",
      "3  f8e41567-0858-4376-ac68-b0701ee23285 2023-07-25 15:38:23+00:00   evt   \n",
      "4  8a9a9b2f-ed28-495d-b344-4d5dd7c7cd3b 2023-07-25 15:38:24+00:00  reco   \n",
      "\n",
      "  strategy type   age gender  country                                 topics  \\\n",
      "0     None  txt  10.0   male  AdaLove         [\"rugby ball\", \"cat\", \"robot\"]   \n",
      "1     None  txt  10.0   male  AdaLove  [\"rugby ball\", \"ship\", \"soccer ball\"]   \n",
      "2     None  img  10.0   male  AdaLove                             rugby ball   \n",
      "3     None  txt  10.0   male  AdaLove         [\"rugby ball\", \"cat\", \"robot\"]   \n",
      "4     None  txt   NaN  unkwn    unkwn   [\"basketball ball\", \"corn\", \"apple\"]   \n",
      "\n",
      "              next_evt_unix  timespent  \n",
      "0 2023-07-25 15:38:21+00:00        5.0  \n",
      "1 2023-07-25 15:38:23+00:00        2.0  \n",
      "2                       NaT        NaN  \n",
      "3 2023-07-25 15:38:23+00:00        0.0  \n",
      "4 2023-07-25 15:38:24+00:00        0.0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import psycopg2\n",
    "\n",
    "conn  = psycopg2.connect(host=\"localhost\", user=\"root\", port=5432, database=\"W9sV6cL2dX\", password=\"E5rG7tY3fH\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# define your query\n",
    "query = \"\"\"\n",
    "        SELECT  \n",
    "    fc.user_id, \n",
    "    fc.item_id, \n",
    "    fc.session_id, \n",
    "    to_timestamp(fc.evnt_stamp) as cur_evt_unix, \n",
    "    fc.type, \n",
    "    fc.strategy, \n",
    "    i.type,\n",
    "    u.age,\n",
    "    u.gender,\n",
    "    u.country,\n",
    "    CONCAT(itx.topics, iti.topic) AS Topics,\n",
    "    to_timestamp(LEAD(evnt_stamp) OVER (\n",
    "            PARTITION BY session_id\n",
    "            ORDER BY\n",
    "              evnt_stamp\n",
    "          )) as next_evt_unix,\n",
    "    ( (LEAD(evnt_stamp) OVER (\n",
    "            PARTITION BY session_id\n",
    "            ORDER BY\n",
    "              evnt_stamp\n",
    "          ) - fc.evnt_stamp)) as Timespent\t  \n",
    "    FROM \n",
    "        public.fct_hourly_metric fc\n",
    "    Inner Join\n",
    "        users u on u.id = fc.user_id\n",
    "    left JOIN \n",
    "        items i ON fc.item_id = i.item_key\n",
    "    LEFT JOIN \n",
    "        item_txt_content itx ON i.item_key = itx.item_key\n",
    "    LEFT JOIN \n",
    "        item_img_content iti ON i.item_key = iti.item_key\n",
    "    order by cur_evt_unix, fc.type  desc\n",
    "        \"\"\"\n",
    "\n",
    "# execute the query and load the result into a DataFrame\n",
    "df = pd.read_sql_query(query, conn)\n",
    "\n",
    "# make sure to close the connection\n",
    "conn.close()\n",
    "\n",
    "# Now your data is in a pandas DataFrame, which you can check by:\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#df to csv\n",
    "df.to_csv('twotowers_source_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>session_id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>topics</th>\n",
       "      <th>country</th>\n",
       "      <th>timespent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21507</td>\n",
       "      <td>0aa69c75-fe3d-4fa4-b7b6-be5ddb84dc97</td>\n",
       "      <td>f8e41567-0858-4376-ac68-b0701ee23285</td>\n",
       "      <td>10.0</td>\n",
       "      <td>male</td>\n",
       "      <td>[\"rugby ball\", \"cat\", \"robot\"]</td>\n",
       "      <td>AdaLove</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21507</td>\n",
       "      <td>e51065ff-bf8e-481e-88a9-a73fe0e97bbb</td>\n",
       "      <td>f8e41567-0858-4376-ac68-b0701ee23285</td>\n",
       "      <td>10.0</td>\n",
       "      <td>male</td>\n",
       "      <td>[\"rugby ball\", \"ship\", \"soccer ball\"]</td>\n",
       "      <td>AdaLove</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21507</td>\n",
       "      <td>cf669ac8-3467-454c-ae6e-d080ac085b4b</td>\n",
       "      <td>f8e41567-0858-4376-ac68-b0701ee23285</td>\n",
       "      <td>10.0</td>\n",
       "      <td>male</td>\n",
       "      <td>rugby ball</td>\n",
       "      <td>AdaLove</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21507</td>\n",
       "      <td>0aa69c75-fe3d-4fa4-b7b6-be5ddb84dc97</td>\n",
       "      <td>f8e41567-0858-4376-ac68-b0701ee23285</td>\n",
       "      <td>10.0</td>\n",
       "      <td>male</td>\n",
       "      <td>[\"rugby ball\", \"cat\", \"robot\"]</td>\n",
       "      <td>AdaLove</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2125</td>\n",
       "      <td>fbf59f88-29a6-4877-9c8e-efc7619c9788</td>\n",
       "      <td>8a9a9b2f-ed28-495d-b344-4d5dd7c7cd3b</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unkwn</td>\n",
       "      <td>[\"basketball ball\", \"corn\", \"apple\"]</td>\n",
       "      <td>unkwn</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                               item_id  \\\n",
       "0    21507  0aa69c75-fe3d-4fa4-b7b6-be5ddb84dc97   \n",
       "1    21507  e51065ff-bf8e-481e-88a9-a73fe0e97bbb   \n",
       "2    21507  cf669ac8-3467-454c-ae6e-d080ac085b4b   \n",
       "3    21507  0aa69c75-fe3d-4fa4-b7b6-be5ddb84dc97   \n",
       "4     2125  fbf59f88-29a6-4877-9c8e-efc7619c9788   \n",
       "\n",
       "                             session_id   age gender  \\\n",
       "0  f8e41567-0858-4376-ac68-b0701ee23285  10.0   male   \n",
       "1  f8e41567-0858-4376-ac68-b0701ee23285  10.0   male   \n",
       "2  f8e41567-0858-4376-ac68-b0701ee23285  10.0   male   \n",
       "3  f8e41567-0858-4376-ac68-b0701ee23285  10.0   male   \n",
       "4  8a9a9b2f-ed28-495d-b344-4d5dd7c7cd3b   NaN  unkwn   \n",
       "\n",
       "                                  topics  country  timespent  \n",
       "0         [\"rugby ball\", \"cat\", \"robot\"]  AdaLove        5.0  \n",
       "1  [\"rugby ball\", \"ship\", \"soccer ball\"]  AdaLove        2.0  \n",
       "2                             rugby ball  AdaLove        NaN  \n",
       "3         [\"rugby ball\", \"cat\", \"robot\"]  AdaLove        0.0  \n",
       "4   [\"basketball ball\", \"corn\", \"apple\"]    unkwn        0.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1= df[['user_id','item_id','session_id','age','gender','topics','country','timespent']]\n",
    "#df1 to csv\n",
    "df1.to_csv('df1.csv', index=False)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all input arrays must have the same shape",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 58\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[39m# Separate features and labels for training set\u001b[39;00m\n\u001b[1;32m     57\u001b[0m train_features \u001b[39m=\u001b[39m [train_data[column]\u001b[39m.\u001b[39mvalues \u001b[39mfor\u001b[39;00m column \u001b[39min\u001b[39;00m columns_to_encode]\n\u001b[0;32m---> 58\u001b[0m train_features\u001b[39m.\u001b[39mappend(np\u001b[39m.\u001b[39;49mstack(train_data[\u001b[39m'\u001b[39;49m\u001b[39mtopics\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mvalues))\n\u001b[1;32m     59\u001b[0m train_labels \u001b[39m=\u001b[39m train_data[\u001b[39m'\u001b[39m\u001b[39mtimespent\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mvalues\n\u001b[1;32m     61\u001b[0m \u001b[39m# Separate features and labels for testing set\u001b[39;00m\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mstack\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/shape_base.py:464\u001b[0m, in \u001b[0;36mstack\u001b[0;34m(arrays, axis, out, dtype, casting)\u001b[0m\n\u001b[1;32m    462\u001b[0m shapes \u001b[39m=\u001b[39m {arr\u001b[39m.\u001b[39mshape \u001b[39mfor\u001b[39;00m arr \u001b[39min\u001b[39;00m arrays}\n\u001b[1;32m    463\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(shapes) \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> 464\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mall input arrays must have the same shape\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    466\u001b[0m result_ndim \u001b[39m=\u001b[39m arrays[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mndim \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    467\u001b[0m axis \u001b[39m=\u001b[39m normalize_axis_index(axis, result_ndim)\n",
      "\u001b[0;31mValueError\u001b[0m: all input arrays must have the same shape"
     ]
    }
   ],
   "source": [
    "# Import the necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "import ast\n",
    "\n",
    "# Load your data\n",
    "data = pd.read_csv('df1.csv')\n",
    "\n",
    "\n",
    "def parse_topics(topics_str):\n",
    "    # If the topics are a string representation of a list\n",
    "    if isinstance(topics_str, str) and topics_str.startswith('[') and topics_str.endswith(']'):\n",
    "        # Strip off the square brackets and split on commas\n",
    "        return topics_str[1:-1].replace('\"', '').replace(\"'\", \"\").split(',')\n",
    "    # If the topics are just a single string\n",
    "    elif isinstance(topics_str, str):\n",
    "        return [topics_str]\n",
    "    else:\n",
    "        # If topics_str is not a string (e.g., it's NaN)\n",
    "        return []\n",
    "\n",
    "# Apply the function to the 'topics' column\n",
    "data['topics'] = data['topics'].apply(parse_topics)\n",
    "\n",
    "\n",
    "# Define columns to be encoded\n",
    "columns_to_encode = ['gender', 'country']\n",
    "\n",
    "# Dictionary to save the label encoders for each column\n",
    "label_encoders = {}\n",
    "\n",
    "# Label encode 'gender' and 'country' columns\n",
    "for col in columns_to_encode:\n",
    "    le = LabelEncoder()\n",
    "    data[col] = le.fit_transform(data[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Get list of all unique topics\n",
    "unique_topics = set()\n",
    "for topics in data['topics']:\n",
    "    for topic in topics:\n",
    "        unique_topics.add(topic)\n",
    "\n",
    "# Dictionary to map topics to integers\n",
    "topic_to_int = {topic: i for i, topic in enumerate(unique_topics)}\n",
    "\n",
    "# Replace topics with their corresponding integers\n",
    "data['topics'] = data['topics'].apply(lambda x: [topic_to_int[topic] for topic in x])\n",
    "\n",
    "# Split data into training and testing sets\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Separate features and labels for training set\n",
    "train_features = [train_data[column].values for column in columns_to_encode]\n",
    "train_features.append(np.stack(train_data['topics'].values))\n",
    "train_labels = train_data['timespent'].values\n",
    "\n",
    "# Separate features and labels for testing set\n",
    "test_features = [test_data[column].values for column in columns_to_encode]\n",
    "test_features.append(np.stack(test_data['topics'].values))\n",
    "test_labels = test_data['timespent'].values\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Define the input layers\n",
    "inputs = [tf.keras.layers.Input(shape=(1,), name=f'{col}_input') for col in columns_to_encode]\n",
    "inputs.append(tf.keras.layers.Input(shape=(None,), name='topics_input'))  # The topics input can have arbitrary length\n",
    "\n",
    "# Define the embedding layers\n",
    "embeddings = [tf.keras.layers.Embedding(input_dim=len(label_encoders[col].classes_), output_dim=10)(input_layer) for col, input_layer in zip(columns_to_encode, inputs)]\n",
    "embeddings.append(tf.keras.layers.Embedding(input_dim=len(unique_topics), output_dim=10)(inputs[-1]))\n",
    "\n",
    "# Flatten the embeddings\n",
    "flattened_embeddings = [tf.keras.layers.Flatten()(embedding) for embedding in embeddings]\n",
    "\n",
    "# Concatenate the flattened embeddings\n",
    "x = tf.keras.layers.Concatenate()(flattened_embeddings)\n",
    "\n",
    "# Add dense layers\n",
    "x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
    "output = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "# Define the model\n",
    "model = tf.keras.models.Model(inputs=inputs, outputs=output)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_features, train_labels, epochs=10, batch_size=32, validation_data=(test_features, test_labels))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prev version 1 V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>session_id</th>\n",
       "      <th>age</th>\n",
       "      <th>topics</th>\n",
       "      <th>timespent</th>\n",
       "      <th>gender_female</th>\n",
       "      <th>gender_male</th>\n",
       "      <th>gender_other</th>\n",
       "      <th>gender_unkwn</th>\n",
       "      <th>...</th>\n",
       "      <th>grapes</th>\n",
       "      <th>guitar</th>\n",
       "      <th>horse</th>\n",
       "      <th>mushroom</th>\n",
       "      <th>robot</th>\n",
       "      <th>rugby ball</th>\n",
       "      <th>ship</th>\n",
       "      <th>soccer ball</th>\n",
       "      <th>tennis racket</th>\n",
       "      <th>truck</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21507</td>\n",
       "      <td>0aa69c75-fe3d-4fa4-b7b6-be5ddb84dc97</td>\n",
       "      <td>f8e41567-0858-4376-ac68-b0701ee23285</td>\n",
       "      <td>0.094737</td>\n",
       "      <td>[rugby ball, cat, robot]</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21507</td>\n",
       "      <td>e51065ff-bf8e-481e-88a9-a73fe0e97bbb</td>\n",
       "      <td>f8e41567-0858-4376-ac68-b0701ee23285</td>\n",
       "      <td>0.094737</td>\n",
       "      <td>[rugby ball, ship, soccer ball]</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21507</td>\n",
       "      <td>cf669ac8-3467-454c-ae6e-d080ac085b4b</td>\n",
       "      <td>f8e41567-0858-4376-ac68-b0701ee23285</td>\n",
       "      <td>0.094737</td>\n",
       "      <td>[rugby ball]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21507</td>\n",
       "      <td>0aa69c75-fe3d-4fa4-b7b6-be5ddb84dc97</td>\n",
       "      <td>f8e41567-0858-4376-ac68-b0701ee23285</td>\n",
       "      <td>0.094737</td>\n",
       "      <td>[rugby ball, cat, robot]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2125</td>\n",
       "      <td>fbf59f88-29a6-4877-9c8e-efc7619c9788</td>\n",
       "      <td>8a9a9b2f-ed28-495d-b344-4d5dd7c7cd3b</td>\n",
       "      <td>0.336842</td>\n",
       "      <td>[basketball ball, corn, apple]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270261</th>\n",
       "      <td>32933</td>\n",
       "      <td>878a12f5-b19f-4c2e-a450-ee460e51fe0b</td>\n",
       "      <td>db14c1ed-e0ac-43ee-aff3-ed8b2fd82004</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>[brocolli, ship, rugby ball]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270262</th>\n",
       "      <td>9552</td>\n",
       "      <td>49000889-bbe4-4a75-a65a-ba362104ed9f</td>\n",
       "      <td>6c321b38-84e5-41f2-931e-87697f9fd1b6</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>[truck, tennis racket, ship]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270263</th>\n",
       "      <td>25962</td>\n",
       "      <td>39525912-af6a-4f04-b4cb-c6533e5bddf7</td>\n",
       "      <td>b7dd68d9-9c64-4927-9ddb-c500ac1c29d0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270264</th>\n",
       "      <td>25962</td>\n",
       "      <td>c4a2de90-e781-4421-9107-14bda0441140</td>\n",
       "      <td>b7dd68d9-9c64-4927-9ddb-c500ac1c29d0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>[robot]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270265</th>\n",
       "      <td>25962</td>\n",
       "      <td>NaN</td>\n",
       "      <td>b7dd68d9-9c64-4927-9ddb-c500ac1c29d0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>270266 rows Ã— 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id                               item_id  \\\n",
       "0         21507  0aa69c75-fe3d-4fa4-b7b6-be5ddb84dc97   \n",
       "1         21507  e51065ff-bf8e-481e-88a9-a73fe0e97bbb   \n",
       "2         21507  cf669ac8-3467-454c-ae6e-d080ac085b4b   \n",
       "3         21507  0aa69c75-fe3d-4fa4-b7b6-be5ddb84dc97   \n",
       "4          2125  fbf59f88-29a6-4877-9c8e-efc7619c9788   \n",
       "...         ...                                   ...   \n",
       "270261    32933  878a12f5-b19f-4c2e-a450-ee460e51fe0b   \n",
       "270262     9552  49000889-bbe4-4a75-a65a-ba362104ed9f   \n",
       "270263    25962  39525912-af6a-4f04-b4cb-c6533e5bddf7   \n",
       "270264    25962  c4a2de90-e781-4421-9107-14bda0441140   \n",
       "270265    25962                                   NaN   \n",
       "\n",
       "                                  session_id       age  \\\n",
       "0       f8e41567-0858-4376-ac68-b0701ee23285  0.094737   \n",
       "1       f8e41567-0858-4376-ac68-b0701ee23285  0.094737   \n",
       "2       f8e41567-0858-4376-ac68-b0701ee23285  0.094737   \n",
       "3       f8e41567-0858-4376-ac68-b0701ee23285  0.094737   \n",
       "4       8a9a9b2f-ed28-495d-b344-4d5dd7c7cd3b  0.336842   \n",
       "...                                      ...       ...   \n",
       "270261  db14c1ed-e0ac-43ee-aff3-ed8b2fd82004  0.526316   \n",
       "270262  6c321b38-84e5-41f2-931e-87697f9fd1b6  0.473684   \n",
       "270263  b7dd68d9-9c64-4927-9ddb-c500ac1c29d0  0.400000   \n",
       "270264  b7dd68d9-9c64-4927-9ddb-c500ac1c29d0  0.400000   \n",
       "270265  b7dd68d9-9c64-4927-9ddb-c500ac1c29d0  0.400000   \n",
       "\n",
       "                                 topics  timespent  gender_female  \\\n",
       "0              [rugby ball, cat, robot]   0.294118            0.0   \n",
       "1       [rugby ball, ship, soccer ball]   0.117647            0.0   \n",
       "2                          [rugby ball]   0.000000            0.0   \n",
       "3              [rugby ball, cat, robot]   0.000000            0.0   \n",
       "4        [basketball ball, corn, apple]   0.000000            0.0   \n",
       "...                                 ...        ...            ...   \n",
       "270261     [brocolli, ship, rugby ball]   0.000000            0.0   \n",
       "270262     [truck, tennis racket, ship]   0.000000            0.0   \n",
       "270263                               []   0.000000            1.0   \n",
       "270264                          [robot]   0.000000            1.0   \n",
       "270265                               []   0.000000            1.0   \n",
       "\n",
       "        gender_male  gender_other  gender_unkwn  ...  grapes  guitar  horse  \\\n",
       "0               1.0           0.0           0.0  ...       0       0      0   \n",
       "1               1.0           0.0           0.0  ...       0       0      0   \n",
       "2               1.0           0.0           0.0  ...       0       0      0   \n",
       "3               1.0           0.0           0.0  ...       0       0      0   \n",
       "4               0.0           0.0           1.0  ...       0       0      0   \n",
       "...             ...           ...           ...  ...     ...     ...    ...   \n",
       "270261          1.0           0.0           0.0  ...       0       0      0   \n",
       "270262          1.0           0.0           0.0  ...       0       0      0   \n",
       "270263          0.0           0.0           0.0  ...       0       0      0   \n",
       "270264          0.0           0.0           0.0  ...       0       0      0   \n",
       "270265          0.0           0.0           0.0  ...       0       0      0   \n",
       "\n",
       "        mushroom  robot  rugby ball  ship  soccer ball  tennis racket  truck  \n",
       "0              0      1           1     0            0              0      0  \n",
       "1              0      0           1     1            1              0      0  \n",
       "2              0      0           1     0            0              0      0  \n",
       "3              0      1           1     0            0              0      0  \n",
       "4              0      0           0     0            0              0      0  \n",
       "...          ...    ...         ...   ...          ...            ...    ...  \n",
       "270261         0      0           1     1            0              0      0  \n",
       "270262         0      0           0     1            0              1      1  \n",
       "270263         0      0           0     0            0              0      0  \n",
       "270264         0      1           0     0            0              0      0  \n",
       "270265         0      0           0     0            0              0      0  \n",
       "\n",
       "[270266 rows x 42 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Import the necessary libraries\n",
    "# # Import the necessary libraries\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, MultiLabelBinarizer\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# import json\n",
    "\n",
    "# # Load your data\n",
    "# data = pd.read_csv('df1.csv')\n",
    "# # Define columns to be encoded\n",
    "# columns_to_encode = ['gender', 'country', 'content_type']\n",
    "\n",
    "# # Dictionary to save the label encoders for each column\n",
    "# label_encoders = {}\n",
    "\n",
    "# # Label encode 'gender', 'country', and 'content_type' columns\n",
    "# for col in columns_to_encode:\n",
    "#     le = LabelEncoder()\n",
    "#     data[col] = le.fit_transform(data[col])\n",
    "#     label_encoders[col] = le\n",
    "\n",
    "# # Ensure topics are integer encoded. Here, we will encode each unique topic to a unique integer.\n",
    "# mlb = MultiLabelBinarizer()\n",
    "# topics_encoded = mlb.fit_transform(data['topics'])\n",
    "# # Create a dictionary to map topics to integers\n",
    "# topic_to_int = {topic: i for i, topic in enumerate(mlb.classes_)}\n",
    "# # Replace topics with their corresponding integers\n",
    "# data['topics'] = data['topics'].apply(lambda x: [topic_to_int[topic] for topic in x])\n",
    "\n",
    "# # Split data into training and testing sets\n",
    "# train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Separate features and labels for training set\n",
    "# train_features = [train_data[column].values for column in columns_to_encode]\n",
    "# train_features.append(np.stack(train_data['topics'].values))\n",
    "# train_labels = train_data['timespent'].values\n",
    "\n",
    "# # Separate features and labels for testing set\n",
    "# test_features = [test_data[column].values for column in columns_to_encode]\n",
    "# test_features.append(np.stack(test_data['topics'].values))\n",
    "# test_labels = test_data['timespent'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Embedding, Input, Dense, Flatten, Concatenate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Encode categorical columns to convert them into numerical\n",
    "# You might want to save these encoders for later when you'll want to make predictions on new data\n",
    "label_encoders = {}\n",
    "for col in ['user_id', 'item_id', 'gender', 'country', 'type', 'Topics']:\n",
    "    le = LabelEncoder()\n",
    "    data[col] = le.fit_transform(data[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "\n",
    "# Split your data into training and testing sets\n",
    "train, test = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the architecture of the User Tower\n",
    "user_input = Input(shape=(1,), dtype=tf.int32, name='user_input')\n",
    "user_embedding = Embedding(input_dim=data['user_id'].nunique(), output_dim=50, name='user_embedding')(user_input)\n",
    "user_embedding = Flatten()(user_embedding)\n",
    "\n",
    "# Add the other user features\n",
    "user_age_input = Input(shape=(1,), dtype=tf.float32, name='user_age_input')\n",
    "user_gender_input = Input(shape=(1,), dtype=tf.int32, name='user_gender_input')\n",
    "user_country_input = Input(shape=(1,), dtype=tf.int32, name='user_country_input')\n",
    "\n",
    "user_features = Concatenate()([user_embedding, user_age_input, user_gender_input, user_country_input])\n",
    "\n",
    "user_tower = Dense(128, activation='relu')(user_features)\n",
    "user_tower = Dense(64, activation='relu')(user_tower)\n",
    "\n",
    "# Define the architecture of the Item Tower\n",
    "item_input = Input(shape=(1,), dtype=tf.int32, name='item_input')\n",
    "item_embedding = Embedding(input_dim=data['item_id'].nunique(), output_dim=50, name='item_embedding')(item_input)\n",
    "item_embedding = Flatten()(item_embedding)\n",
    "\n",
    "# Add the other item features\n",
    "item_type_input = Input(shape=(1,), dtype=tf.int32, name='item_type_input')\n",
    "item_topics_input = Input(shape=(1,), dtype=tf.int32, name='item_topics_input')\n",
    "\n",
    "item_features = Concatenate()([item_embedding, item_type_input, item_topics_input])\n",
    "\n",
    "item_tower = Dense(128, activation='relu')(item_features)\n",
    "item_tower = Dense(64, activation='relu')(item_tower)\n",
    "\n",
    "# Combine the outputs of the two towers\n",
    "output = Concatenate()([user_tower, item_tower])\n",
    "output = Dense(32, activation='relu')(output)\n",
    "output = Dense(1, activation='sigmoid')(output)\n",
    "\n",
    "# Define the model\n",
    "model = Model(inputs=[user_input, user_age_input, user_gender_input, user_country_input, item_input, item_type_input, item_topics_input], outputs=output)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "# Note: you might need to adjust the input data format based on how you've preprocessed your data\n",
    "model.fit([train['user_id'], train['age'], train['gender'], train['country'], train['item_id'], train['type'], train['Topics']], train['Timespent'], epochs=5, batch_size=32)\n",
    "\n",
    "# Evaluate the model\n",
    "model.evaluate([test['user_id'], test['age'], test['gender'], test['country'], test['item_id'], test['type'], test['Topics']], test['Timespent'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
