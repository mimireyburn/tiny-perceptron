{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19daebd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "eea4f733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['male', 'female', 'other']\n",
      "[55, 27, 23, 56, 91, 58, 8, 87, 74, 54, 29, 71, 68, 4, 34, 51, 96, 80, 70, 52, 83, 67, 63, 90, 10, 35, 45, 6, 84, 86, 39, 92, 93, 89, 69, 36, 31, 50, 60, 14, 66, 22, 59, 13, 65, 2, 16, 62, 75, 73, 44, 11, 42, 88, 82, 41, 46, 40, 43, 53, 32, 9, 7, 38, 15, 79, 48, 12, 26, 85, 72, 78, 57, 24, 81, 61, 19, 77, 25, 94, 30, 21, 49, 47, 3, 17, 20, 37, 28, 33, 1, 76, 5, 18, 64]\n",
      "['FibonacciFlats', 'Neuropolis', 'TensorPeak', 'TuringLake', 'unkwn', 'AdaLove', 'AlgoBay', 'BayesianBourg', 'GraphTown']\n",
      "Gender Encoded:  torch.Size([40000])\n",
      "Country Encoded:  torch.Size([40000])\n",
      "Age Normalized:  40000\n",
      "Gender Encoded:  torch.Size([40000, 16])\n",
      "Country Encoded:  torch.Size([40000, 16])\n",
      "Age Encoded:  torch.Size([40000, 16])\n",
      "torch.Size([40000, 48])\n",
      "torch.Size([496340, 48])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import psycopg2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from psycopg2.extras import DictCursor\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "# save to user_data\n",
    "\n",
    "connection = psycopg2.connect(host=\"localhost\", user=\"root\", port=5432, database=\"W9sV6cL2dX\", password=\"E5rG7tY3fH\")\n",
    "cursor = connection.cursor(cursor_factory=DictCursor)\n",
    "\n",
    "select_query = \"SELECT id, gender, country, age FROM users WHERE gender <> 'unkwn'\"\n",
    "cursor.execute(select_query)\n",
    "user_data = cursor.fetchall()\n",
    "\n",
    "data = {}\n",
    "data['gender'] = [d[1] for d in user_data]\n",
    "data['country'] = [d[2] for d in user_data]\n",
    "data['age'] = [d[3] for d in user_data]\n",
    "\n",
    "data\n",
    "\n",
    "select_query = \"SELECT DISTINCT country FROM users;\"\n",
    "select_query_age = \"SELECT DISTINCT age FROM users WHERE age is not Null;\"\n",
    "\n",
    "cursor.execute(select_query)\n",
    "db_countries = cursor.fetchall()\n",
    "\n",
    "cursor.execute(select_query_age)\n",
    "db_age = cursor.fetchall()\n",
    "\n",
    "# define your categories\n",
    "genders = ['male', 'female', 'other']\n",
    "ages = [age[0] for age in db_age]\n",
    "countries = [country[0] for country in db_countries]\n",
    "\n",
    "print(genders)\n",
    "print(ages)\n",
    "print(countries)\n",
    "\n",
    "gender_encoder = LabelEncoder()\n",
    "gender_encoder.fit(genders)\n",
    "country_encoder = LabelEncoder()\n",
    "country_encoder.fit(countries)\n",
    "# normalise age by subtracting the mean and dividing by the SD\n",
    "age_scaler = StandardScaler()\n",
    "\n",
    "# Convert data to tensors\n",
    "gender_tensor = torch.tensor(gender_encoder.transform(data['gender']), dtype=torch.long)\n",
    "country_tensor = torch.tensor(country_encoder.transform(data['country']), dtype=torch.long)\n",
    "age_normalised = torch.tensor(age_scaler.fit_transform(np.array(data['age']).reshape(-1, 1)), dtype=torch.float32)\n",
    "\n",
    "# With these lines:\n",
    "gender_embed = nn.Embedding(len(genders), 16)  # Adjusted embedding dimension\n",
    "country_embed = nn.Embedding(len(countries), 16)  # Adjusted embedding dimension\n",
    "age_embed = nn.Linear(1, 16)  # Adding a linear layer to project age to the same dimension\n",
    "\n",
    "# Transform the data\n",
    "gender_encoded = gender_embed(gender_tensor)\n",
    "country_encoded = country_embed(country_tensor)\n",
    "age_encoded = age_embed(age_normalised.unsqueeze(1)).squeeze(1)\n",
    "\n",
    "print(\"Gender Encoded: \", gender_tensor.shape)\n",
    "print(\"Country Encoded: \", country_tensor.shape)\n",
    "print(\"Age Normalized: \", len(age_normalised))\n",
    "\n",
    "print(\"Gender Encoded: \", gender_encoded.shape)\n",
    "print(\"Country Encoded: \", country_encoded.shape)\n",
    "print(\"Age Encoded: \", age_encoded.shape)\n",
    "\n",
    "user_embeddings = torch.cat((gender_encoded, country_encoded, age_encoded), dim=1)\n",
    "print(user_embeddings.shape)  # Should now be torch.Size([40000, 48])\n",
    "\n",
    "\n",
    "# Import the necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "import ast\n",
    "\n",
    "# Load your data\n",
    "data = pd.read_csv('df1.csv')\n",
    "\n",
    "\n",
    "def parse_topics(topics_str):\n",
    "    # If the topics are a string representation of a list\n",
    "    if isinstance(topics_str, str) and topics_str.startswith('[') and topics_str.endswith(']'):\n",
    "        # Strip off the square brackets and split on commas\n",
    "        return topics_str[1:-1].replace('\"', '').replace(\"'\", \"\").split(',')\n",
    "    # If the topics are just a single string\n",
    "    elif isinstance(topics_str, str):\n",
    "        return [topics_str]\n",
    "    else:\n",
    "        # If topics_str is not a string (e.g., it's NaN)\n",
    "        return []\n",
    "\n",
    "# Apply the function to the 'topics' column\n",
    "data['topics'] = data['topics'].apply(parse_topics)\n",
    "\n",
    "\n",
    "# Define columns to be encoded\n",
    "columns_to_encode = ['gender', 'country']\n",
    "\n",
    "# Dictionary to save the label encoders for each column\n",
    "label_encoders = {}\n",
    "\n",
    "# Label encode 'gender' and 'country' columns\n",
    "for col in columns_to_encode:\n",
    "    le = LabelEncoder()\n",
    "    data[col] = le.fit_transform(data[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Get list of all unique topics\n",
    "unique_topics = set()\n",
    "for topics in data['topics']:\n",
    "    for topic in topics:\n",
    "        unique_topics.add(topic)\n",
    "\n",
    "# Dictionary to map topics to integers\n",
    "topic_to_int = {topic: i for i, topic in enumerate(unique_topics)}\n",
    "\n",
    "# Create a column for each unique topic\n",
    "for topic in unique_topics:\n",
    "    data[topic] = data['topics'].apply(lambda topics: int(topic in topics))\n",
    "\n",
    "# Convert the topic columns to tensors\n",
    "topic_tensors = {topic: torch.tensor(data[topic].values, dtype=torch.long) for topic in unique_topics}\n",
    "\n",
    "# Define the embedding layers for each topic\n",
    "topic_embeds = {topic: nn.Embedding(2, 1) for topic in unique_topics}  # Using embedding dimension of 1\n",
    "\n",
    "# Transform the topic data\n",
    "encoded_topics = {topic: topic_embeds[topic](topic_tensors[topic]) for topic in unique_topics}\n",
    "\n",
    "# Concatenate all the features together\n",
    "item_embeddings = torch.cat([encoded_topics[topic] for topic in encoded_topics] + [torch.tensor(data[col].values, dtype=torch.long).unsqueeze(1) for col in columns_to_encode], dim=1)\n",
    "\n",
    "print(item_embeddings.shape)  # This will print the shape of your final item embeddings tensor\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6192892e",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "TwoTowerNetwork.__init__() takes 4 positional arguments but 5 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[62], line 59\u001b[0m\n\u001b[1;32m     55\u001b[0m         prob \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msigmoid(cosine_similarity)\n\u001b[1;32m     57\u001b[0m         \u001b[39mreturn\u001b[39;00m prob\n\u001b[0;32m---> 59\u001b[0m model \u001b[39m=\u001b[39m TwoTowerNetwork(\u001b[39m48\u001b[39;49m, \u001b[39m48\u001b[39;49m, \u001b[39m48\u001b[39;49m, \u001b[39m48\u001b[39;49m)\n\u001b[1;32m     60\u001b[0m optimizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mAdam(model\u001b[39m.\u001b[39mparameters())\n\u001b[1;32m     61\u001b[0m criterion \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mBCELoss()\n",
      "\u001b[0;31mTypeError\u001b[0m: TwoTowerNetwork.__init__() takes 4 positional arguments but 5 were given"
     ]
    }
   ],
   "source": [
    "\n",
    "item_embeddings.shape\n",
    "\n",
    "# Let's assume we're training on a subset of 20,000 user-item pairs as we pass in 2000 items and 1000 users to model\n",
    "num_pairs = 48\n",
    "\n",
    "# Generate random expected interactions for these pairs\n",
    "# We will assume that 0 means the user did not interact with the item (spent less than 5s)\n",
    "# and 1 means the user did interact with the item (spent more than 5s).\n",
    "# expected_interactions = np.random.randint(2, size=num_pairs)\n",
    "# Convert to a tensor\n",
    "expected_interactions = torch.randint(0, 2, (num_pairs,), dtype=torch.float32)\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class TwoTowerNetwork(nn.Module):\n",
    "    def __init__(self, user_input_dim, item_input_dim, output_dim):\n",
    "        super(TwoTowerNetwork, self).__init__()\n",
    "\n",
    "        hidden_dim = 128  # example value, adjust based on your requirement\n",
    "\n",
    "        # User tower\n",
    "        self.user_fc1 = nn.Linear(user_input_dim, hidden_dim)\n",
    "        self.user_fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "        # Item tower\n",
    "        self.item_fc1 = nn.Linear(item_input_dim, hidden_dim)\n",
    "        self.item_fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, user_input, item_input):\n",
    "        # User tower\n",
    "        user_output = self.user_fc1(user_input)\n",
    "        user_output = self.relu(user_output)\n",
    "        user_output = self.user_fc2(user_output)\n",
    "\n",
    "        # Item tower\n",
    "        item_output = self.item_fc1(item_input)\n",
    "        item_output = self.relu(item_output)\n",
    "        item_output = self.item_fc2(item_output)\n",
    "\n",
    "        # Normalize the embeddings (this is necessary for cosine similarity)\n",
    "        user_output = F.normalize(user_output, dim=1)\n",
    "        item_output = F.normalize(item_output, dim=1)\n",
    "\n",
    "        # Compute cosine similarity\n",
    "        # Cosine similarity is the dot product of the normalized vectors\n",
    "        cosine_similarity = torch.sum(user_output * item_output, dim=1)\n",
    "\n",
    "        # Convert the cosine similarity to a probability (between 0 and 1)\n",
    "        prob = torch.sigmoid(cosine_similarity)\n",
    "\n",
    "        return prob\n",
    "\n",
    "model = TwoTowerNetwork(48, 48, 48)\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "for epoch in range(30):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()  # Clear the gradients at the beginning of each loop\n",
    "    output = model(user_embeddings[:num_pairs], item_embeddings[:num_pairs])  # Use num_pairs here\n",
    "    loss = criterion(output, expected_interactions)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f\"Epoch: {epoch+1}, Loss: {loss.item()}\")  # print the loss for each epoch\n",
    "\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "151d464d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "optimizer got an empty parameter list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[61], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[39m# your architecture code here...\u001b[39;00m\n\u001b[1;32m     11\u001b[0m model \u001b[39m=\u001b[39m TwoTowerNetwork(\u001b[39m48\u001b[39m, \u001b[39m48\u001b[39m, \u001b[39m48\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m optimizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49moptim\u001b[39m.\u001b[39;49mAdam(model\u001b[39m.\u001b[39;49mparameters())\n\u001b[1;32m     13\u001b[0m criterion \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mBCELoss()\n\u001b[1;32m     15\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m30\u001b[39m):\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py:33\u001b[0m, in \u001b[0;36mAdam.__init__\u001b[0;34m(self, params, lr, betas, eps, weight_decay, amsgrad, foreach, maximize, capturable, differentiable, fused)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mInvalid weight_decay value: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(weight_decay))\n\u001b[1;32m     29\u001b[0m defaults \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(lr\u001b[39m=\u001b[39mlr, betas\u001b[39m=\u001b[39mbetas, eps\u001b[39m=\u001b[39meps,\n\u001b[1;32m     30\u001b[0m                 weight_decay\u001b[39m=\u001b[39mweight_decay, amsgrad\u001b[39m=\u001b[39mamsgrad,\n\u001b[1;32m     31\u001b[0m                 maximize\u001b[39m=\u001b[39mmaximize, foreach\u001b[39m=\u001b[39mforeach, capturable\u001b[39m=\u001b[39mcapturable,\n\u001b[1;32m     32\u001b[0m                 differentiable\u001b[39m=\u001b[39mdifferentiable, fused\u001b[39m=\u001b[39mfused)\n\u001b[0;32m---> 33\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(params, defaults)\n\u001b[1;32m     35\u001b[0m \u001b[39mif\u001b[39;00m fused:\n\u001b[1;32m     36\u001b[0m     \u001b[39mif\u001b[39;00m differentiable:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py:187\u001b[0m, in \u001b[0;36mOptimizer.__init__\u001b[0;34m(self, params, defaults)\u001b[0m\n\u001b[1;32m    185\u001b[0m param_groups \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(params)\n\u001b[1;32m    186\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(param_groups) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 187\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39moptimizer got an empty parameter list\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(param_groups[\u001b[39m0\u001b[39m], \u001b[39mdict\u001b[39m):\n\u001b[1;32m    189\u001b[0m     param_groups \u001b[39m=\u001b[39m [{\u001b[39m'\u001b[39m\u001b[39mparams\u001b[39m\u001b[39m'\u001b[39m: param_groups}]\n",
      "\u001b[0;31mValueError\u001b[0m: optimizer got an empty parameter list"
     ]
    }
   ],
   "source": [
    "# Make synthetic data\n",
    "user_embeddings = torch.randn(200, 48)\n",
    "item_embeddings = torch.randn(200, 48)\n",
    "expected_interactions = torch.randint(0, 2, (200,), dtype=torch.float32)\n",
    "\n",
    "class TwoTowerNetwork(nn.Module):\n",
    "    def __init__(self, user_input_dim, item_input_dim, output_dim):\n",
    "        super(TwoTowerNetwork, self).__init__()\n",
    "        # your architecture code here...\n",
    "\n",
    "model = TwoTowerNetwork(48, 48, 48)\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "for epoch in range(30):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()  # Clear the gradients at the beginning of each loop\n",
    "    output = model(user_embeddings, item_embeddings)\n",
    "    loss = criterion(output, expected_interactions)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f\"Epoch: {epoch+1}, Loss: {loss.item()}\")  # print the loss for each epoch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0fa69266",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b5eb5397",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (100x48 and 3x128)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 52\u001b[0m\n\u001b[1;32m     50\u001b[0m model\u001b[39m.\u001b[39mtrain()\n\u001b[1;32m     51\u001b[0m \u001b[39m# user_input and item_input are your input tensors, expected_interactions is [1,0,0..] where 1 signifies the user spent more than 5s on an item\u001b[39;00m\n\u001b[0;32m---> 52\u001b[0m output \u001b[39m=\u001b[39m model(user_embeddings[:\u001b[39m100\u001b[39;49m], item_embeddings[:\u001b[39m200\u001b[39;49m])\n\u001b[1;32m     53\u001b[0m loss \u001b[39m=\u001b[39m criterion(output, expected_interactions)\n\u001b[1;32m     54\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[40], line 23\u001b[0m, in \u001b[0;36mTwoTowerNetwork.forward\u001b[0;34m(self, user_input, item_input)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, user_input, item_input):\n\u001b[1;32m     22\u001b[0m     \u001b[39m# User tower\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m     user_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49muser_fc1(user_input)\n\u001b[1;32m     24\u001b[0m     user_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu(user_output)\n\u001b[1;32m     25\u001b[0m     user_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muser_fc2(user_output)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (100x48 and 3x128)"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "18b88c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([200, 512])\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
